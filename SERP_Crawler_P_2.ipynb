{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOV6llKlVmu8MV6O08VTvg3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonmoy-khanal/SERP-Crawler/blob/main/SERP_Crawler_P_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Function to scrape Google search results for YouTube links\n",
        "def scrape_google_results(query):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "    url = f\"https://www.google.com/search?q={query}&num=100\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    search_results = []\n",
        "    for result in soup.find_all('div', class_='yuRUbf'):\n",
        "        link = result.a.get('href')\n",
        "        if \"youtube.com\" in link:\n",
        "            search_results.append(link)\n",
        "    return search_results\n",
        "\n",
        "# Function to scrape YouTube links for a given search query\n",
        "def scrape_youtube_links(query, max_results):\n",
        "    results = []\n",
        "    num_pages = max_results // 100\n",
        "    for page in range(num_pages + 1):\n",
        "        start = page * 100\n",
        "        search_query = f'site:youtube.com {query}'\n",
        "        search_results = scrape_google_results(search_query)\n",
        "        results.extend(search_results)\n",
        "        if len(results) >= max_results:\n",
        "            break\n",
        "    return results[:max_results]\n",
        "\n",
        "# Main function to scrape YouTube links and output the results in JSON format\n",
        "def main():\n",
        "    query = \"https://www.google.com/search?q=site%3Ayoutube.com+openinapp.co&oq=site&aqs=chrome.1.69i57j69i59l3j0i512j69i60j69i61j69i60.7822j0j7&sourceid=chrome&ie=UTF-8\"\n",
        "    max_results = 10000\n",
        "    results = scrape_youtube_links(query, max_results)\n",
        "    output = {'youtube_links': results}\n",
        "\n",
        "    if len(results) == 0:\n",
        "        output = {'youtube_links': []}\n",
        "\n",
        "    with open('youtube_links.json', 'w') as file:\n",
        "        json.dump(output, file, indent=4)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "thoughH0PoOS"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}